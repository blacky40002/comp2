{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd754b39-202b-47a2-b7c8-a25c1824c7fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:45:04.233718Z",
     "start_time": "2024-04-16T10:45:04.228707Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c1eba-8c1c-44ff-b7c7-4f4212e3506d",
   "metadata": {},
   "source": [
    "# Task PreTENS: Presupposed Taxonomies: Evaluating Neural Network Semantics)\n",
    "\n",
    "- [Link Documentazione](http://www.italianlp.it/resources/semeval-2022-pretens-evaluating-neural-networks-on-presuppositional-semantic-knowledge/)\n",
    "\n",
    "Il task è diviso in due sotto-task.\n",
    "\n",
    "1) Classificazione di frasi come accettabili o non accettabili\n",
    "2) Predizione (regressione) del punteggio medio di accettabilità che varia da 1 a 7, assegnato alle frasi da annotatori umani.\n",
    "\n",
    "Il dataset è stato costruito per 3 lingue: inglese, francese ed italiano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69d89c-5a09-4422-b378-4ffca82c7297",
   "metadata": {},
   "source": [
    "Cercheremo di risolvere il secondo sotto-task per l'italiano.\n",
    "\n",
    "Tag-IT era un task di classificazione di documenti, questo è un task di **regressione** su **frasi**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3291c1c-1d55-4433-9287-3564098f35b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "I file di training utilizzati per questo laboratorio sono:\n",
    "- https://github.com/shammur/SemEval2022Task3/blob/main/data/train/train_subtask-2/it/It-Subtask2-fold_0.tsv\n",
    "- https://github.com/shammur/SemEval2022Task3/blob/main/data/train/train_subtask-2/it/It-Subtask2-fold_1.tsv\n",
    "    \n",
    "Il file di test è:\n",
    "- https://github.com/shammur/SemEval2022Task3/blob/main/data/test/official_test_set_with_labels/subtask-2/It-Subtask2-scores.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12803d-562e-45da-acef-5aa24e7a6cb2",
   "metadata": {},
   "source": [
    "# Unisco i due file di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a4a842-c5ce-4d57-8309-f425de7b1420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:45:04.241888Z",
     "start_time": "2024-04-16T10:45:04.234635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_files = ['data/PreTENS/src/It-Subtask2-fold_0.tsv', 'data/PreTENS/src/It-Subtask2-fold_1.tsv']\n",
    "out_path = 'data/PreTENS/src/It-Subtask2-train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc82a3d-93c6-44c4-a072-fdc8626f2fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:45:04.249201Z",
     "start_time": "2024-04-16T10:45:04.242445Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(out_path, 'w+') as out_file:\n",
    "    for line in open(src_files[0], 'r'):\n",
    "        out_file.write(line)\n",
    "    first = True\n",
    "    for line in open(src_files[1], 'r'):\n",
    "        if not first:\n",
    "            out_file.write(line)\n",
    "        first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b718cc-4c8f-45a3-b60e-4bee6bdde6e1",
   "metadata": {},
   "source": [
    "# Preparo l'input per Profiling-UD\n",
    "\n",
    "Creo un file per ogni frase, usando come nome del file l'id della frase.\n",
    "\n",
    "Creo a parte un file in cui ogni id è associato allo score da predire e allo split (train/test) in cui si trova la frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb10a3f7-8936-48a1-953e-1c9438a65dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:45:04.257901Z",
     "start_time": "2024-04-16T10:45:04.250217Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'data/PreTENS/src/It-Subtask2-train.tsv'\n",
    "test_path = 'data/PreTENS/src/It-Subtask2-scores.tsv'\n",
    "profiling_input_dir = 'data/PreTENS/preprocessed_dataset/profiling_input'\n",
    "sentences_info_path = 'data/PreTENS/preprocessed_dataset/sentences_info.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f81cacc94b0ac2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:45:04.265185Z",
     "start_time": "2024-04-16T10:45:04.258626Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(profiling_input_dir):\n",
    "    os.makedirs(profiling_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd5aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_info_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60d711",
   "metadata": {},
   "source": [
    "### Preprocessing del training set e del test set\n",
    "\n",
    "Creazione di un file per ogni frase e un dizionario che contiene le info (score e split) di ogni frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c767fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open(train_path, 'r'):    \n",
    "    splitted_line = line.strip().split('\\t')\n",
    "    if splitted_line[0] != 'ID':\n",
    "        sent_id = f'train_{splitted_line[0]}'\n",
    "        sentence = splitted_line[1]\n",
    "        score = float(splitted_line[2])\n",
    "                \n",
    "        out_path = os.path.join(profiling_input_dir, f'{sent_id}.txt')\n",
    "        with open(out_path, 'w+') as out_file:\n",
    "            out_file.write(sentence)\n",
    "    \n",
    "        sentences_info_dict[sent_id] = {'score': score, 'split': 'train'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac86fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open(test_path, 'r'):    \n",
    "    splitted_line = line.strip().split('\\t')\n",
    "    if splitted_line[0] != 'ID':\n",
    "        sent_id = f'test_{splitted_line[0]}'\n",
    "        sentence = splitted_line[2]\n",
    "        score = float(splitted_line[3])\n",
    "                \n",
    "        out_path = os.path.join(profiling_input_dir, f'{sent_id}.txt')\n",
    "        with open(out_path, 'w+') as out_file:\n",
    "            out_file.write(sentence)\n",
    "    \n",
    "        sentences_info_dict[sent_id] = {'score': score, 'split': 'test'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650b91d-90b6-4c3f-ae31-2c1549a35709",
   "metadata": {},
   "source": [
    "Creazione del file che contiene id della frase, score e split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a27bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5f30ff-fd12-47cc-80b0-aa55841f9a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:45:04.335842Z",
     "start_time": "2024-04-16T10:45:04.327900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(sentences_info_path, 'w') as out_file:\n",
    "    json.dump(sentences_info_dict, out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
